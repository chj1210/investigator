# 專案計畫書：警政單位應用人工智慧偵查金融經濟犯罪平台

**文件版本：** 1.0
**最後更新日期：** 2025-06-26

---

## 1. 專案概述

### 1.1. 專案願景 (Vision)

打造一個領先的智慧化金融犯罪偵查平台，透過 AI 賦能警政單位，顯著提升金融案件的偵查效率與準確性，成為打擊經濟犯罪的關鍵利器。

### 1.2. 主要目標 (Goals)

本平台旨在達成以下可量化的關鍵目標：

*   **效率提升：** 將平均案件調查週期縮短 50%。
*   **精準打擊：** 提高新型態或隱匿性高的異常交易模式識別率達 30% 以上。
*   **決策支援：** 提供直觀的數據視覺化儀表板，輔助管理者進行資源調度與成效評估。
*   **知識傳承：** 建立標準化的數位案件管理流程，將成功的偵查經驗轉化為可複製的分析模型。

### 1.3. 專案範疇 (Scope)

本專案將專注於開發一個整合數據分析、AI 模型與案件管理的內部平台。範疇包含從外部金融數據的接入、處理、分析，到最終透過前端應用程式呈現給不同角色的使用者。

---

## 2. 使用者與核心功能

### 2.1. 目標使用者 (Target Users)

| 角色 | 主要職責 |
| :--- | :--- |
| **第一線偵查員** | 負責具體案件的調查、金流追蹤與證據搜集。 |
| **數據分析師** | 負責數據探索、模型開發與驗證，支援複雜案件。 |
| **案件管理者/高階長官** | 負責案件分派、進度監控與整體偵查成效評估。 |

### 2.2. 核心功能 (Core Features)

1.  **金流追蹤與分析：**
    *   提供使用者介面，輸入特定帳戶、時間區間等條件，查詢相關交易紀錄。
    *   視覺化呈現單一或多個帳戶間的金流路徑。
    *   自動標示出符合特定規則（如：大額、快進快出）的交易。

2.  **異常交易模式識別：**
    *   利用機器學習模型（如：孤立森林、自編碼器）自動偵測偏離常態的交易行為。
    *   提供模型預警清單，並允許分析師對預警進行標記與反饋，以優化模型。

3.  **關聯網絡分析：**
    *   以圖形化方式呈現人、帳戶、公司、交易之間的多維度複雜關係。
    *   提供節點擴展、路徑搜尋等互動式分析功能，協助偵查員挖掘潛在共犯結構。

4.  **案件管理與進度追蹤：**
    *   提供數位化的案件建立、分派、進度回報功能。
    *   每個案件可關聯相關的帳戶、交易紀錄、分析報告與證據文件。
    *   提供案件時間軸，清晰記錄案件的每一個重要節點。

5.  **數據視覺化儀表板：**
    *   為管理者提供宏觀儀表板，展示整體案件數量、類型分佈、平均偵辦時長等 KPI。
    *   提供各類犯罪模式的統計分析圖表。

---

## 3. 技術架構與設計

### 3.1. 建議技術棧 (Technology Stack)

| 分層 | 技術/框架 | 選擇理由 |
| :--- | :--- | :--- |
| **前端** | React.js | 生態系成熟，社群活躍，擁有豐富的資料視覺化函式庫 (如 D3.js, ECharts)。 |
| **後端** | Python (FastAPI) | Python 為 AI/ML 開發首選，FastAPI 提供高效能、異步 API 開發能力。 |
| **API 閘道** | Kong | 成熟的開源 API Gateway，易於管理微服務的路由、認證與流量控制。 |
| **資料庫** | PostgreSQL, Neo4j | PostgreSQL 處理結構化資料；Neo4j 專精於圖形關係分析，是關聯網絡的核心。 |
| **數據處理** | Apache Spark | 強大的分散式運算框架，能高效處理 TB 等級的金融交易數據。 |
| **訊息佇列** | Apache Kafka | 作為數據接入的緩衝區，實現系統間的解耦與高可靠性數據傳輸。 |
| **AI/ML** | TensorFlow/PyTorch | 主流深度學習框架，擁有豐富的預訓練模型與工具。 |

### 3.2. 高層次系統架構圖 (High-Level Architecture)

```mermaid
graph TD
    subgraph 用戶端 (Client)
        A[前端應用 (React)]
    end

    subgraph API 層
        B[API 閘道 (Kong)]
    end

    subgraph 後端微服務 (Backend Microservices)
        C[案件管理服務]
        D[使用者認證服務]
        E[金流分析服務]
        F[AI 模型服務 API]
    end

    subgraph 資料處理層 (Data Processing)
        G[數據接入 (Kafka)]
        H[資料處理引擎 (Spark)]
    end

    subgraph AI/ML 平台
        I[模型訓練 (TensorFlow/PyTorch)]
        J[模型部署 (TF Serving)]
    end

    subgraph 資料儲存層 (Data Storage)
        K[PostgreSQL (案件資料)]
        L[Neo4j (關聯網絡)]
        M[數據湖 (Data Lake)]
    end

    %% Data Flow
    A --> B
    B --> C & D & E & F

    subgraph 外部數據源
        N[金融機構數據]
    end

    N --> G --> H
    H --> K & L & M

    M & L & K --> I --> J
    F --> J

    C --> K
    D --> K
    E --> K & L
```

### 3.3. 數據流說明 (Data Flow)

1.  **數據接入：** 來自各金融機構的交易數據透過 `Kafka` 進入系統。
2.  **數據處理：** `Spark` 引擎對原始數據進行清洗、轉換、特徵工程，並分別存入 `PostgreSQL`、`Neo4j` 與 `數據湖`。
3.  **模型訓練：** 數據分析師使用 `數據湖` 中的資料，透過 `TensorFlow/PyTorch` 進行模型訓練。
4.  **模型部署：** 訓練完成的模型被部署到 `TF Serving`，並透過 `AI 模型服務 API` 提供預測能力。
5.  **後端服務：** 各微服務（案件管理、金流分析等）處理前端請求，並與資料庫互動。`金流分析服務` 會調用 `AI 模型服務` 進行異常偵測。
6.  **前端呈現：** `React` 前端應用程式透過 `API 閘道` 請求後端服務，將分析結果與案件資料以視覺化方式呈現給使用者。

---

## 4. 專案里程碑 (Milestones)

| 階段 | 預計時程 | 主要交付成果 |
| :--- | :--- | :--- |
| **第一階段：基礎建設與核心功能** | 3 個月 | 數據接入流程、案件管理系統、基礎金流查詢功能。 |
| **第二階段：AI 導入與關聯分析** | 3 個月 | 異常交易偵測模型 (v1)、關聯網絡分析介面。 |
| **第三階段：儀表板與系統優化** | 2 個月 | 管理者儀表板、使用者反饋優化、壓力測試。 |
| **第四階段：內部試點與上線** | 1 個月 | 小規模內部試用、系統部署與正式上線。 |